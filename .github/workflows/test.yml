name: Test

on:
  workflow_dispatch:
  push:
    branches: ["main"]
    paths:
      - "Sources/**"
      - "Tests/**"
      - "Package.swift"
      - "Example/**"
      - ".github/workflows/test.yml"
  pull_request:
    types: [opened, reopened, synchronize, ready_for_review]
    branches: ["main"]
    paths:
      - "Sources/**"
      - "Tests/**"
      - "Package.swift"
      - "Example/**"
      - ".github/workflows/test.yml"

env:
  DEVELOPER_DIR: "/Applications/Xcode_16.4.app/Contents/Developer"

jobs:
  test-macos:
    name: Test on macOS (${{ matrix.test-type }})
    runs-on: macos-15
    strategy:
      fail-fast: false
      matrix:
        test-type: [Llama, MLX]
    env:
      TEST_RUNNER_GITHUB_MODEL_CACHE: "${{ github.workspace }}/model_cache"
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Cache model file
        id: cache-model
        uses: actions/cache@v4
        with:
          path: model_cache
          key: model_cache

      - name: Run ${{ matrix.test-type }} tests
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 30
          max_attempts: 3
          retry_on: error
          command: TEST_RUNNER_GITHUB_ACTIONS_TEST="${{ matrix.test-type }}" xcodebuild test -scheme LocalLLMClient-Package -destination 'platform=macOS'

  build-example-macos:
    runs-on: macos-15
    needs: test-macos
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Build Example app for macOS
        working-directory: Example
        run: xcodebuild build -project LocalLLMClientExample.xcodeproj -scheme LocalLLMClientExample -destination 'platform=macOS' CODE_SIGN_IDENTITY="-"

  build-example-ios:
    runs-on: macos-15
    needs: test-macos
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Build Example app for iOS
        working-directory: Example
        run: xcodebuild build -project LocalLLMClientExample.xcodeproj -scheme LocalLLMClientExample -destination 'platform=iOS Simulator,name=iPhone 16 Pro' CODE_SIGN_IDENTITY="-"

  test-ubuntu-x86_64:
    runs-on: ubuntu-latest
    needs: test-macos
    env:
      GITHUB_MODEL_CACHE: "${{ github.workspace }}/model_cache"
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Cache model files
        id: cache-model
        uses: actions/cache@v4
        with:
          path: model_cache
          key: model_cache

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev

      - name: Install Swift
        shell: bash
        run: |
          curl -O "https://download.swift.org/swiftly/linux/swiftly-$(uname -m).tar.gz" && \
          tar zxf "swiftly-$(uname -m).tar.gz" && \
          ./swiftly init --assume-yes --no-modify-profile --skip-install --quiet-shell-followup && \
          . ${SWIFTLY_HOME_DIR:-~/.local/share/swiftly}/env.sh && \
          hash -r
          swiftly install 6.1
          echo "SWIFTLY_HOME_DIR=${SWIFTLY_HOME_DIR}" >>"${GITHUB_ENV}"
          echo "SWIFTLY_BIN_DIR=${SWIFTLY_BIN_DIR}" >>"${GITHUB_ENV}"
          echo "${SWIFTLY_BIN_DIR}" >>"${GITHUB_PATH}"

      - name: Setup llama.cpp binaries
        id: setup-llama
        run: |
          LLAMA_VERSION=$(./scripts/get_llama_version.sh)
          mkdir -p ${{ github.workspace }}/lib

          # Download and extract llama.cpp binaries
          LLAMA_URL="https://github.com/ggml-org/llama.cpp/releases/download/${LLAMA_VERSION}/llama-${LLAMA_VERSION}-bin-ubuntu-x64.zip"
          echo "Downloading llama.cpp binaries from: $LLAMA_URL"
          curl -L $LLAMA_URL -o llama-bin.zip
          unzip -j llama-bin.zip "*.so" -d "${{ github.workspace }}/lib"
          ls -la ${{ github.workspace }}/lib

      - name: Build package
        run: LDFLAGS="-L${{ github.workspace }}/lib" swift build
        # LD_LIBRARY_PATH="$(pwd)/lib" ./.build/debug/localllm -m "${{ github.workspace }}/model_cache/huggingface/models/ggml-org/SmolVLM-256M-Instruct-GGUF/SmolVLM-256M-Instruct-Q8_0.gguf" "Hello"

      - name: Run tests
        run: LDFLAGS="-L${{ github.workspace }}/lib" LD_LIBRARY_PATH="${{ github.workspace }}/lib" swift test
        if: false # TODO:
